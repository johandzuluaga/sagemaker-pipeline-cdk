# ğŸš¢ Titanic Survival Prediction â€“ SageMaker MLOps Pipeline

This project demonstrates a complete MLOps workflow using AWS SageMaker to train, evaluate, register, and deploy a machine learning model for predicting Titanic passenger survival.

---

## ğŸ§  Problem Statement

Predict whether a passenger survived the Titanic disaster using features such as class, age, fare, and more. The model is trained and deployed using a robust, automated pipeline on AWS SageMaker.

---

## ğŸ“ Project Structure

```

.
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train.py                # Training script used by SageMaker
â”‚   â”œâ”€â”€ inference.py            # Entry point for deployed model
â”‚   â”œâ”€â”€ model\_utils.py          # Wrapper for inference preprocessing
â”‚   â””â”€â”€ **init**.py             # To make the scripts folder a module
â”œâ”€â”€ deployment/
â”‚   â”œâ”€â”€ deploy\_endpoint.py      # Script to deploy model as endpoint
â”‚   â””â”€â”€ invoke\_endpoint.py      # Script to test endpoint prediction
â”œâ”€â”€ pipeline/
â”‚   â””â”€â”€ pipeline\_definition.py  # Defines the SageMaker pipeline
â”œâ”€â”€ processed\_data/             # Input data for the pipeline
â”œâ”€â”€ raw\_data/                   # Original Titanic dataset
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt

````

---

## ğŸ”§ Technologies Used

- **AWS SageMaker**: Pipelines, Training, Model Registry, Endpoints
- **scikit-learn**: Model training
- **SageMaker Python SDK**
- **Boto3**: For deployment and endpoint invocation
- **joblib**: Model serialization

---

## âš™ï¸ Pipeline Overview

### âœ… Steps

1. **Preprocessing**
   - Raw CSV â†’ Cleaned features saved to S3
2. **Training**
   - Logistic regression using `scikit-learn`
   - Saves model as `model.joblib`
   - Calculates and logs metrics (accuracy)
3. **Model Registration**
   - Registers model in SageMaker Model Registry with metrics
4. **Deployment**
   - Deploys the approved model as a real-time endpoint

---

## ğŸ“Š Metrics

- Model Accuracy: **~75.5%**
- Stored in S3 as `metrics.json`
- Registered in SageMaker Model Registry

---

## ğŸš€ Endpoint Invocation

Use the deployed endpoint to make real-time predictions. Example:

```bash
python deployment/invoke_endpoint.py
````

Sample input:

```csv
3,1,22.0,0,0,7.25,0
```

Prediction Output:

```text
Prediction: [1]
```

---

## âœ… Skills Demonstrated

* âœ… End-to-end MLOps pipeline design
* âœ… Real-time endpoint deployment using Boto3
* âœ… Custom inference wrappers and model serialization
* âœ… SageMaker Pipeline & Model Registry integration
* âœ… Error debugging and AWS log analysis

---

## ğŸ“ How to Run This Project

1. Upload data to S3
2. Run the pipeline:

```bash
python pipeline/pipeline_definition.py
```

3. Deploy and test the endpoint:

```bash
python deployment/deploy_endpoint.py
python deployment/invoke_endpoint.py
```

---

## ğŸ“Œ Notes

* The pipeline automatically registers and approves the model.
* The custom wrapper ensures all predictions work even with a single input row.
* Metrics are embedded in the model package for auditability.

---

## ğŸ“¬ Contact

Created by **\[Johan Zuluaga]**.
For questions, feel free to reach out via \[johandzuluaga@gmail.com].

---

